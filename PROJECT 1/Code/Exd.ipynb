{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ce2c04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and functions:\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Import our own implementations\n",
    "import importlib, gradient_descent, OLS, prepare_data, polynomial_features\n",
    "importlib.reload(gradient_descent)\n",
    "importlib.reload(OLS)\n",
    "importlib.reload(prepare_data)\n",
    "importlib.reload(polynomial_features)\n",
    "\n",
    "from prepare_data import prepare_data\n",
    "from polynomial_features import polynomial_features\n",
    "from gradient_descent import gradient_descent_OLS, gradient_descent_Ridge, momentum_gradient_descent_OLS\n",
    "from OLS import OLS_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f52380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations:  71123\n",
      "Vanlig GD:  [ 0.28512452 -0.0535955  -0.70385688  0.12489643  0.50825878 -0.07108439]\n",
      "Number of iterations:  9369\n",
      "GD med momentum:  [ 0.28512452 -0.05363078 -0.70385857  0.12499882  0.5082594  -0.07115547]\n",
      "Closed-form OLS coefficients:  [ 0.28512452 -0.05363465 -0.70385875  0.12501007  0.50825947 -0.07116328]\n"
     ]
    }
   ],
   "source": [
    "# Test, GD with momentum, OLS :\n",
    "x, y, x_train, x_test, y_train, y_test, y_noisy = prepare_data()\n",
    "\n",
    "p = 5\n",
    "\n",
    "X_plot = polynomial_features(x, p, intercept=False)\n",
    "X_train = polynomial_features(x_train, p, intercept=False)\n",
    "X_test  = polynomial_features(x_test, p, intercept=False)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_test_s  = scaler.transform(X_test)\n",
    "X_plot_s  = scaler.transform(X_plot)\n",
    "\n",
    "beta = gradient_descent_OLS(X_train_s, y_train, eta=0.01, num_iters=100000, print_num_iters=True)\n",
    "print(\"Vanlig GD: \", beta)\n",
    "beta_momentum = momentum_gradient_descent_OLS(X_train_s, y_train, eta=0.01, num_iters=100000, print_num_iters=True, momentum=0.9)\n",
    "beta_closed = OLS_parameters(X_train_s, y_train)\n",
    "print(\"GD med momentum: \", beta_momentum)\n",
    "\n",
    "print(\"Closed-form OLS coefficients: \", beta_closed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca59dfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test, GD with momentum, Ridge:\n",
    "x, y, x_train, x_test, y_train, y_test, y_noisy = prepare_data()\n",
    "\n",
    "p = 5\n",
    "\n",
    "X_plot = polynomial_features(x, p, intercept=True)\n",
    "X_train = polynomial_features(x_train, p, intercept=True)\n",
    "X_test  = polynomial_features(x_test, p, intercept=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[:, 1:])\n",
    "\n",
    "X_train_s = np.hstack([X_train[:, [0]], scaler.transform(X_train[:, 1:])])\n",
    "X_test_s  = np.hstack([X_test[:,  [0]], scaler.transform(X_test[:,  1:])])\n",
    "X_plot_s  = np.hstack([X_plot[:,  [0]], scaler.transform(X_plot[:,  1:])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e50656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "x, y, x_train, x_test, y_train, y_test, y_noisy = prepare_data()\n",
    "\n",
    "deg_max = 15\n",
    "MSE=[]\n",
    "R2_score= []\n",
    "for p in range(1, deg_max+1):\n",
    "    X_plot = polynomial_features(x, p, intercept=True)\n",
    "    X_train = polynomial_features(x_train, p, intercept=True)\n",
    "    X_test  = polynomial_features(x_test, p, intercept=True)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train[:, 1:])\n",
    "\n",
    "    X_train_s = np.hstack([X_train[:, [0]], scaler.transform(X_train[:, 1:])])\n",
    "    X_test_s  = np.hstack([X_test[:,  [0]], scaler.transform(X_test[:,  1:])])\n",
    "    X_plot_s  = np.hstack([X_plot[:,  [0]], scaler.transform(X_plot[:,  1:])])\n",
    "    \n",
    "    beta = gradient_descent_OLS(X_train_s, y_train)\n",
    "    y_pred = X_test_s @ beta\n",
    "    MSE.append(mean_squared_error(y_test, y_pred))\n",
    "    R2_score.append(r2_score(y_true=y_test, y_pred=y_pred))\n",
    "    plt.plot(x, y)\n",
    "    plt.plot(x, X_plot_s@beta)\n",
    "plt.show()   \n",
    "degrees = np.arange(1, deg_max+1)\n",
    "plt.plot(degrees, MSE, label=\"MSE\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(degrees, R2_score, label=\"R2-score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c000638e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
